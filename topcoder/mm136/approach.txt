## Code
[Final Solution](https://github.com/FakePsyho/cpcontests/blob/master/topcoder/mm136/HungryKnights.cpp) - Really messy as I gave up on maintaining readable code rather early in the contest.
[Submit #10](https://github.com/FakePsyho/cpcontests/blob/master/topcoder/mm136/HungryKnights_submit10.cpp) - Early version of my final approach. If you ignore the initial greedy part, it should be very easy to follow. 


## Initial Approach
At the start of the contest I tried global greedy where at each step I choose a chain that gets the most points. The chains are generated by a random walk-like algorithm. Each knight can have a "setup" of up to 3 moves. I always choose a random knight that has the shortest possible setup. I ran this process many times from scratch and choose the best outcome.
I was surprised that after including 1-setup moves this was able to generate chains that were able to use up to 90% of knights of particular color. From here, I thought that my solution is going to perform very poorly on medium/big tests as (1) random walks are very inefficient use of resources for longer chains  (2) global greedy is not able to find the proper balance between all of the chains.


## Final Approach
* SA that simultanously tries to build all C chains at the same time.
 - State: C chains (one of each color) and required setups.
 - Transition: randomize color (**c**) and position (**pos**); cut chain **c** at **pos** and regenerate the remaining part of the chain using random walk; no collisions are allowed (either with other chains or their setups) - during random walk generation I assume that everything else is fixed.
 - Evaluation: **score** * (**time_passed** ^ (**wasted_knights** * constant / N)), where **score** is score according to the problem statement, **time_passed** represents passed time and it's within [0, 1] range and **wasted_knights** is the total number of used knights for setup moves. This means that at the start of SA I tried to avoid wasting knights as much as I can.
* After SA is done, I use my initial approach in order to use the remaining knights that were not used during my initial C chains. This is suboptimal, but the initial chains cover 98-99% of score for all tests except for the very small ones.

This approach is fairly simple, but unfortunately it has multiple drawbacks. Mainly, it's very easy to get stuck in a local maximum, since my state transition is not able to generate small changes. It's also going to perform very poorly on small tests where going for long chains is often suboptimal. 

Instead of coming up with a better general approach I decided to patch my SA with a bunch of tricks to alleviate some of its disadvantages.


## Tricks & Optimizations
In order of importance:
* Aggresive temperature schedule: I had a very narrow range of values for temperature schedule that worked well. Almost every time I added a new feature to the code I had to readjust my temperature schedule, quite often changing the whole formula.
* Multiple runs up till 20-30% of the full schedule and then taking the best run and running it to the end. This could have been generalized to a beam search like approach if I had multiple steps.
* Instead of running my greedy only at the end, run it multiple times at various times. Drastically improved my scores on the small tests.
* Very heavy parameter tuning on 5K tests (at the end of the contest).
* Additional state transitions:
	- Instead of using random walk (that always tries to make the chain as big as it can) sometimes just cut the chain
	- Only perturb setups of an existing chain
	- Instead of cutting the chain and regenerating one side, try to generate a subchain that starts at **pos** and rejoins the chain **c** at another point, hopefully extending it.
* Sacrificing some colors at the start of the SA (1 color for C=4,5 and 2 colors for C=6,7)


## Example Results
```
Test Case #1:  Score = 143.0
Test Case #2:  Score = 22709.0
Test Case #3:  Score = 22102.0
Test Case #4:  Score = 917.0
Test Case #5:  Score = 209.0
Test Case #6:  Score = 1495.0
Test Case #7:  Score = 2792.0
Test Case #8:  Score = 14505.0
Test Case #9:  Score = 61291.0
Test Case #10: Score = 43528.0
```

I believe the results might change quite a bit based on the unknown distribution of the provisional tests. My solution probably outperforms most people on bigger tests, but I'd imagine my results for N=6..10 are rather poor.